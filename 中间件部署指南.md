# Bella中间件部署指南

## 问题分析

经过仔细检查原有配置，发现之前的方案确实遗漏了一些关键的初始化逻辑。以下是对比分析和正确的部署方案：

## 中间件初始化差异对比

### 1. MySQL初始化差异

**原有分别部署:**
- Workflow: 自动挂载 `../api/sql:/docker-entrypoint-initdb.d`，包含完整的表结构
- File API: 自动挂载 `../api/sql:/docker-entrypoint-initdb.d`，包含完整的表结构

**统一部署问题:**
- 之前方案只创建了数据库和用户，但没有执行具体的表结构创建
- 缺少Workflow和File API各自的表结构初始化

### 2. Elasticsearch初始化差异

**原有Workflow部署:**
- 包含Elasticsearch索引模板创建
- 自动创建 `workflow_run_log_*` 索引模板

**统一部署问题:**
- 我的方案缺少了Elasticsearch服务和相关初始化

### 3. MinIO初始化差异

**原有分别部署:**
- 各自下载mc客户端并创建对应的bucket
- 设置不同的访问密钥

**统一部署问题:**
- 需要同时创建两个bucket并设置正确的权限

## 正确的中间件部署方案

### 第一步：准备文件结构

```bash
bella-deployment/
├── .env.infrastructure
├── .env.workflow  
├── .env.file-api
├── docker-compose.infrastructure.yml
├── docker-compose.gateway.yml
├── docker-compose.workflow.yml
├── docker-compose.file-api.yml
├── infrastructure/
│   ├── mysql/
│   │   └── init/
│   │       ├── 01-create-databases.sql
│   │       ├── 02-workflow-schema.sql      # 来自workflow/api/sql/init.sql
│   │       ├── 03-workflow-updates.sql     # 来自workflow/api/sql/update*.sql
│   │       ├── 04-file-api-schema.sql      # 来自file-api/api/sql/01-init.sql  
│   │       └── 05-file-api-updates.sql     # 来自file-api/api/sql/*update*.sql
│   ├── kafka/
│   │   └── scripts/
│   │       └── setup-topics.sh
│   ├── minio/
│   │   └── scripts/
│   │       └── init-buckets.sh
│   ├── elasticsearch/
│   │   └── scripts/
│   │       └── init-elasticsearch.sh
│   └── workflow-logs/                      # Kafka Connect日志收集目录
└── deploy.sh
```

### 第二步：修正的基础设施配置

#### 修正的 docker-compose.infrastructure.yml

```yaml
name: bella-infrastructure
version: "3.8"

networks:
  bella-network:
    driver: bridge

services:
  mysql:
    image: mysql:8.0
    container_name: bella-mysql
    ports:
      - "${MYSQL_PORT:-3306}:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD:-root}
    volumes:
      - mysql-data:/var/lib/mysql
      # 挂载完整的SQL初始化脚本
      - ./infrastructure/mysql/init:/docker-entrypoint-initdb.d
    command: >
      --default-authentication-plugin=mysql_native_password 
      --character-set-server=utf8mb4 
      --collation-server=utf8mb4_0900_ai_ci
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD:-root}"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - bella-network

  redis:
    image: redis:7-alpine
    container_name: bella-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-bella123}
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-bella123}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 10
    networks:
      - bella-network

  # 添加Elasticsearch (workflow需要)
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.7
    container_name: bella-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "${ELASTICSEARCH_HTTP_PORT:-9200}:9200"
      - "${ELASTICSEARCH_TRANSPORT_PORT:-9300}:9300"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
      - ./infrastructure/elasticsearch/scripts:/scripts
    healthcheck:
      test: ["CMD", "curl", "-s", "-f", "http://localhost:9200/_cluster/health"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - bella-network
    entrypoint: ["/bin/bash", "-c"]
    command: >
      "chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/data && 
      /usr/local/bin/docker-entrypoint.sh eswrapper & 
      sleep 30 && /scripts/init-elasticsearch.sh"

  kafka:
    image: docker.io/bitnamilegacy/kafka:3.4.1
    container_name: bella-kafka
    user: "1001:0"
    ports:
      - "${KAFKA_PLAINTEXT_PORT:-9092}:9092"
      - "${KAFKA_CONTROLLER_PORT:-9093}:9093"
      - "${KAFKA_EXTERNAL_PORT:-19092}:19092"
    environment:
      # KRaft settings
      KAFKA_CFG_NODE_ID: 1
      KAFKA_CFG_PROCESS_ROLES: controller,broker
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: '1@kafka:9093'
      KAFKA_CLUSTER_ID: 'BellaUnifiedKafka001'
      # Listeners
      KAFKA_CFG_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,EXTERNAL://0.0.0.0:19092
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://${KAFKA_EXTERNAL_HOST:-localhost}:19092
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      # Other settings
      KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CFG_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: 'true'
      ALLOW_PLAINTEXT_LISTENER: 'yes'
      # Topic配置
      WORKFLOW_RUN_LOG_TOPIC: ${WORKFLOW_RUN_LOG_TOPIC:-workflow_run_log}
      FILE_API_TOPIC: ${FILE_API_TOPIC:-bella_file_api}
    volumes:
      - kafka-data:/bitnami/kafka
      - ./infrastructure/kafka/scripts:/scripts
      # 关键：workflow日志收集目录
      - ./infrastructure/workflow-logs:/workflow-logs
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server kafka:9092 --list | grep -E '(workflow_run_log|bella_file_api)'"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 60s
    command: >
      bash -c "/opt/bitnami/scripts/kafka/entrypoint.sh /opt/bitnami/scripts/kafka/run.sh &
      sleep 30 && /scripts/setup-topics.sh"
    networks:
      - bella-network

  minio:
    image: minio/minio:latest
    container_name: bella-minio
    ports:
      - "${MINIO_API_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ACCESS_KEY:-bella_admin}
      - MINIO_ROOT_PASSWORD=${MINIO_SECRET_KEY:-bella123456}
      # 两个服务的bucket配置
      - WORKFLOW_S3_BUCKET=${WORKFLOW_S3_BUCKET:-bella-workflow}
      - FILE_API_S3_BUCKET=${FILE_API_S3_BUCKET:-bella-file-api}
    volumes:
      - minio-data:/data
      - ./infrastructure/minio/scripts:/scripts
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - bella-network
    entrypoint: ["/bin/sh"]
    command: >
      -c "minio server /data --console-address ':9001' &
      sleep 20 && /scripts/init-buckets.sh"

volumes:
  mysql-data:
  redis-data:
  kafka-data:
  minio-data:
  elasticsearch-data:
```

### 第三步：完整的初始化脚本

#### MySQL数据库初始化 (infrastructure/mysql/init/01-create-databases.sql)

```sql
-- 01-create-databases.sql
-- 创建数据库和用户
CREATE DATABASE IF NOT EXISTS bella_workflow CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;
CREATE DATABASE IF NOT EXISTS bella_file_api CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;

-- 创建用户
CREATE USER IF NOT EXISTS 'bella_workflow'@'%' IDENTIFIED BY 'bella123';
CREATE USER IF NOT EXISTS 'bella_user'@'%' IDENTIFIED BY '123456';

-- 授权
GRANT ALL PRIVILEGES ON bella_workflow.* TO 'bella_workflow'@'%';
GRANT ALL PRIVILEGES ON bella_file_api.* TO 'bella_user'@'%';

FLUSH PRIVILEGES;
```

#### 复制原有表结构 (需手动操作)

```bash
# 复制workflow表结构
cp /path/to/bella-workflow/api/sql/init.sql ./infrastructure/mysql/init/02-workflow-schema.sql

# 在文件开头添加数据库选择
echo "USE bella_workflow;" > temp.sql
cat ./infrastructure/mysql/init/02-workflow-schema.sql >> temp.sql
mv temp.sql ./infrastructure/mysql/init/02-workflow-schema.sql

# 复制file-api表结构  
cp /path/to/bella-file-api/api/sql/01-init.sql ./infrastructure/mysql/init/04-file-api-schema.sql

# 在文件开头添加数据库选择
echo "USE bella_file_api;" > temp.sql
cat ./infrastructure/mysql/init/04-file-api-schema.sql >> temp.sql
mv temp.sql ./infrastructure/mysql/init/04-file-api-schema.sql

# 合并更新脚本
cat /path/to/bella-workflow/api/sql/update*.sql > ./infrastructure/mysql/init/03-workflow-updates.sql
cat /path/to/bella-file-api/api/sql/*update*.sql > ./infrastructure/mysql/init/05-file-api-updates.sql
```

#### Elasticsearch初始化 (infrastructure/elasticsearch/scripts/init-elasticsearch.sh)

```bash
#!/bin/bash

echo "=== Elasticsearch 统一初始化 ==="

# 等待 Elasticsearch 启动
until curl -s http://localhost:9200/_cluster/health; do
  echo "等待 Elasticsearch 启动..."
  sleep 10
done

# 创建 workflow_run_log 索引模板
echo "创建 workflow_run_log 索引模板..."
curl -X PUT "localhost:9200/_index_template/workflow_run_log_template" -H 'Content-Type: application/json' -d'
{
  "index_patterns": ["workflow_run_log_*"],
  "template": {
    "settings": {
      "number_of_shards": 1,
      "number_of_replicas": 0
    },
    "mappings": {
      "properties": {
        "timestamp": {"type": "date"},
        "level": {"type": "keyword"},
        "message": {"type": "text", "analyzer": "standard"},
        "workflow_id": {"type": "keyword"},
        "node_id": {"type": "keyword"},
        "execution_id": {"type": "keyword"}
      }
    }
  }
}'

echo "Elasticsearch 初始化完成!"
```

### 第四步：部署操作步骤

#### 方式1：手动分步部署

```bash
# 1. 准备环境变量文件
cp .env.infrastructure.example .env.infrastructure
cp .env.workflow.example .env.workflow  
cp .env.file-api.example .env.file-api

# 编辑环境变量文件，设置正确的密码和配置

# 2. 准备MySQL初始化脚本
./prepare-mysql-init.sh  # 执行上面的复制脚本

# 3. 创建网络
docker network create bella-network

# 4. 启动基础设施
docker-compose --env-file .env.infrastructure -f docker-compose.infrastructure.yml up -d

# 5. 等待初始化完成（重要！）
echo "等待基础设施初始化完成..."
sleep 180

# 6. 验证基础设施
./verify-infrastructure.sh

# 7. 启动网关
docker-compose --env-file .env.infrastructure -f docker-compose.gateway.yml up -d

# 8. 启动业务服务
docker-compose --env-file .env.workflow -f docker-compose.workflow.yml up -d
docker-compose --env-file .env.file-api -f docker-compose.file-api.yml up -d
```

#### 方式2：一键部署脚本

```bash
#!/bin/bash
# deploy-middleware.sh

set -e

echo "=== Bella中间件一键部署 ==="

# 检查环境变量文件
if [ ! -f ".env.infrastructure" ]; then
    echo "创建 .env.infrastructure 文件..."
    cp .env.infrastructure.example .env.infrastructure
    echo "请编辑 .env.infrastructure 文件后重新运行"
    exit 1
fi

# 准备MySQL初始化脚本
echo "准备MySQL初始化脚本..."
./prepare-mysql-init.sh

# 创建必要目录
mkdir -p infrastructure/workflow-logs
chmod 777 infrastructure/workflow-logs

# 创建网络
echo "创建Docker网络..."
docker network create bella-network 2>/dev/null || echo "网络已存在"

# 启动基础设施
echo "启动基础设施服务..."
docker-compose --env-file .env.infrastructure -f docker-compose.infrastructure.yml up -d

# 等待初始化
echo "等待基础设施初始化完成（约3-5分钟）..."
sleep 300

# 验证基础设施
echo "验证基础设施..."
docker exec bella-mysql mysql -u root -proot -e "SHOW DATABASES;" | grep -E "(bella_workflow|bella_file_api)"
docker exec bella-redis redis-cli -a bella123 ping
docker exec bella-kafka kafka-topics.sh --bootstrap-server localhost:9092 --list | grep -E "(workflow_run_log|bella_file_api)"
curl -s http://localhost:9200/_cluster/health
curl -s http://localhost:9000/minio/health/live

echo "=== 中间件部署完成 ==="
echo "MySQL: localhost:3306"
echo "Redis: localhost:6379" 
echo "Kafka: localhost:9092"
echo "Elasticsearch: http://localhost:9200"
echo "MinIO: http://localhost:9000 (console: http://localhost:9001)"
```

### 第五步：验证部署

```bash
#!/bin/bash
# verify-infrastructure.sh

echo "=== 验证基础设施部署 ==="

# 检查容器状态
echo "1. 检查容器状态..."
docker ps --format "table {{.Names}}\t{{.Status}}" | grep bella

# 检查MySQL
echo "2. 检查MySQL数据库..."
docker exec bella-mysql mysql -u root -proot -e "SHOW DATABASES;" | grep -E "(bella_workflow|bella_file_api)"
docker exec bella-mysql mysql -u bella_workflow -pbella123 -D bella_workflow -e "SHOW TABLES;" | wc -l
docker exec bella-mysql mysql -u bella_user -p123456 -D bella_file_api -e "SHOW TABLES;" | wc -l

# 检查Redis
echo "3. 检查Redis..."
docker exec bella-redis redis-cli -a bella123 ping

# 检查Kafka
echo "4. 检查Kafka topics..."
docker exec bella-kafka kafka-topics.sh --bootstrap-server localhost:9092 --list

# 检查Elasticsearch
echo "5. 检查Elasticsearch..."
curl -s http://localhost:9200/_cluster/health | jq .status
curl -s http://localhost:9200/_index_template/workflow_run_log_template | jq .index_templates[0].name

# 检查MinIO
echo "6. 检查MinIO buckets..."
docker exec bella-minio mc ls minio/

echo "=== 验证完成 ==="
```

## 关键注意事项

1. **MySQL初始化顺序很重要**：数据库创建→用户创建→表结构→数据更新
2. **Kafka日志收集目录**：必须确保 `infrastructure/workflow-logs` 目录存在且有正确权限
3. **Elasticsearch索引模板**：必须在Workflow服务启动前创建
4. **等待时间**：基础设施初始化需要充足的时间（3-5分钟）
5. **健康检查**：每个服务都要验证健康状态后再启动下一个

这样修正后的方案确保了与原有单独部署完全一致的初始化逻辑。